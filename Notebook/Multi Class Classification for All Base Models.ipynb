{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import os \n",
    "import time \n",
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "#ISIC 2019 25000 IMAGES DATASET LOCATION\n",
    "train_path = \"/home/mrb685/Datasets/Thesis Final Dataset/train/\"\n",
    "val_path  = \"/home/mrb685/Datasets/Thesis Final Dataset/val/\"\n",
    "test_path = \"/home/mrb685/Datasets/Thesis Final Dataset/test/\"\n",
    "\n",
    "CATEGORIES = [\"NV\", \"MEL\", \"BCC\", \"BKL\", \"AK\", \"SCC\", \"VASC\", \"DF\"]\n",
    "\n",
    "\n",
    "\n",
    "# name used to save  \n",
    "model_name = \"all_base_\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "### CALLBACKS \n",
    "\n",
    "# tensorboard callback \n",
    "tensorboard_name = f\"Multimodal_skin_lesion_{model_name}\"\n",
    "tensorboard =  tf.keras.callbacks.TensorBoard(log_dir=f'logs/{tensorboard_name}')\n",
    "\n",
    "\n",
    "# model checkpoint callback \n",
    "checkpoint_path = f\"/home/mrb685/CheckPoints/{model_name}/cp.ckpt\" \n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "\n",
    "if not os.path.isfile(checkpoint_path):\n",
    "    open(checkpoint_path, 'w').close()\n",
    "        \n",
    "\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                mode='max')\n",
    "\n",
    "lr_on_plateau_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                  patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor='val_accuracy', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocess Data <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "\"\"\"\n",
    "    Define early stop behaviour\n",
    "\"\"\"\n",
    "class CustomMetricsAndEarlyStop(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        self.best = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(f\"Log: {logs}\")\n",
    "        val_acc = logs['val_accuracy']\n",
    "\n",
    "        \n",
    "        current = val_acc\n",
    "        if np.greater(current, self.best):\n",
    "            save_path = f\"/home/mrb685/Saved Models/{model_name}.h5\"\n",
    "            print(f\"val_accuracy improved from {self.best} to {current}. Saving model!\")\n",
    "            self.model.save(save_path)\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better (less).\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "                self.model.set_weights(self.best_weights)\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self): # Py3\n",
    "        with self.lock:\n",
    "            return next(self.it)\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Random crop large images \n",
    "\"\"\"\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "@threadsafe_generator\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_crop_generator)\n",
    "for x in range(10):\n",
    "    plt.imshow(X[x])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train Models<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MODEL \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, ResNet101V2, ResNet152, DenseNet121, DenseNet169, DenseNet201\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7 \n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# \"VGG19\", \"ResNet50\", \"ResNet152\", \"DenseNet121\", \"DenseNet201\", \"efficientnet_b0\", \n",
    "#               \"efficientnet_b1\", \"efficientnet_b2\", \"efficientnet_b3\", \"efficientnet_b4\"\n",
    "# \"efficientnet_b5\", \"efficientnet_b6\"\n",
    "\n",
    "# (16, 256, 224), (16, 256, 224), (16, 256, 224), (16, 256, 224), (8, 256, 224), \n",
    "#                  (8, 256, 224), (8, 256, 240), (8, 300, 260), (8, 350, 300), (8, 400, 380)\n",
    "\n",
    "base_names = [\"efficientnet_b0\"]\n",
    "datagen_param = [(4, 400, 224)]\n",
    "for i in range(len(base_names)):\n",
    "    \n",
    "    BATCH_SIZE, IMG_SIZE, IMG_CROP_SIZE = datagen_param[i]\n",
    "    \n",
    "    name = base_names[i]\n",
    "    if name == \"VGG19\":\n",
    "        base = VGG19(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"ResNet50\":\n",
    "        base = ResNet50(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"ResNet101V2\":\n",
    "        base = ResNet101V2(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"ResNet152\":\n",
    "        base = ResNet152(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"DenseNet121\":\n",
    "        base = DenseNet121(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"DenseNet169\":\n",
    "        base = DenseNet169(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"DenseNet201\":\n",
    "        base = DenseNet201(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"efficientnet_b0\":\n",
    "        base = EfficientNetB0(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"efficientnet_b1\":\n",
    "        base = EfficientNetB1(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"efficientnet_b2\":\n",
    "        base = EfficientNetB2(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"efficientnet_b3\":\n",
    "        base = EfficientNetB3(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"efficientnet_b4\":\n",
    "        base = EfficientNetB4(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"efficientnet_b5\":\n",
    "        base = EfficientNetB5(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"efficientnet_b6\":\n",
    "        base = EfficientNetB6(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    if name == \"efficientnet_b7\":\n",
    "        base = EfficientNetB7(input_shape=(IMG_CROP_SIZE,IMG_CROP_SIZE,3),weights=\"imagenet\",include_top=False)\n",
    "    \n",
    "    \n",
    "    model_name = f\"base_isic_randcrop_{name}\"\n",
    "    print(\"---------------------------------\")\n",
    "    print(name)\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    np.random.seed(1234)\n",
    "    x = base.output\n",
    "    x = Flatten()(x) \n",
    "    predictions = Dense(8, activation='softmax',name='output_layer')(x)\n",
    "    \n",
    "    model = Model(base.inputs, predictions)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    dot_img_file = f'model_arch_{name}.png'\n",
    "    tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
    "    \n",
    "    continue \n",
    "    nLayers = len(model.layers)\n",
    "#     print(nLayers)\n",
    "    \n",
    "    freeze_layers = int(nLayers * 0.20)\n",
    "    \n",
    "    for l in range(freeze_layers):\n",
    "        model.layers[l].trainable = False\n",
    "        \n",
    "        \n",
    "#     for layer in model.layers: \n",
    "#         print(layer.trainable)\n",
    "    \n",
    "    BATCH_SIZE, IMG_SIZE, IMG_CROP_SIZE = datagen_param[i]\n",
    "    \n",
    "    print(f\"Datagen Param: {BATCH_SIZE}, {IMG_SIZE}, {IMG_CROP_SIZE}\")\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                                 rotation_range=90,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 brightness_range=(0.8, 1.2),\n",
    "                                validation_split=0.2)\n",
    "\n",
    "    # datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
    "    # val_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        directory=train_path_isic,\n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle = True,\n",
    "        classes=CATEGORIES,\n",
    "        subset=\"training\",\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        directory = train_path_isic,\n",
    "        shuffle = True,\n",
    "        subset=\"validation\",\n",
    "        classes=CATEGORIES,\n",
    "        class_mode = \"categorical\")\n",
    "\n",
    "    train_crop_generator = crop_generator(train_generator, IMG_CROP_SIZE)\n",
    "    val_crop_generator = crop_generator(val_generator, IMG_CROP_SIZE)\n",
    "    \n",
    "    # Run model \n",
    "    \n",
    "    metrics = CustomMetricsAndEarlyStop(10)\n",
    "\n",
    "    # Add the following code anywhere in your machine learning file\n",
    "    # experiment = Experiment(api_key=\"ufQQBm4PhfVWxcwobrFapECw8\",\n",
    "    #                         project_name=\"skin-lesion-classification\", workspace=\"rsd96\")\n",
    "    import time\n",
    "    import multiprocessing\n",
    "    t=time.time()\n",
    "    \n",
    "    # import comet_ml in the top of your file\n",
    "    from comet_ml import Experiment\n",
    "    \n",
    "#     Add the following code anywhere in your machine learning file\n",
    "    experiment = Experiment(api_key=\"ufQQBm4PhfVWxcwobrFapECw8\",\n",
    "                        project_name=\"skin-lesion-classification\", workspace=\"rsd96\")\n",
    "    \n",
    "    experiment.set_name(model_name)\n",
    "    print(train_generator.samples)\n",
    "    hist = model.fit(train_crop_generator,\n",
    "                               validation_data = val_crop_generator,\n",
    "                               epochs=100,\n",
    "                               shuffle=True,\n",
    "                               workers = multiprocessing.cpu_count(),\n",
    "                               callbacks = [lr_on_plateau_callback, metrics],\n",
    "                               steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "                               validation_steps=val_generator.samples // BATCH_SIZE)\n",
    "\n",
    "    experiment.end()\n",
    "    print('Training time: %s' % (time.time() - t))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save model \n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model sensitivity')\n",
    "plt.ylabel('sensitivity')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# model.save(f\"{model_name}.model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test Trained Models<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data generator \n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    directory=test_path,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle = True,\n",
    "    classes=CATEGORIES,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, auc, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_names = [\"VGG19\", \"ResNet50\", \"ResNet152\", \"DenseNet121\", \"DenseNet201\",\n",
    "               \"efficientnet_b0\", \"efficientnet_b1\", \"efficientnet_b2\", \"efficientnet_b3\", \"efficientnet_b4\"]\n",
    "\n",
    "# model_names = [\"efficientnet_b4\"]\n",
    "for name in model_names: \n",
    "    print(\"---------------------------------\")\n",
    "    print(name)\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "#     layers = [\"25\", \"50\", \"75\"]\n",
    "#     for layer in layers:\n",
    "    model_name = f\"base_isic_randcrop_{name}\" \n",
    "    model = load_model(f\"/home/mrb685/Saved Models/{model_name}.h5\")\n",
    "\n",
    "\n",
    "    num_of_test_samples = 1651\n",
    "\n",
    "    #Confution Matrix and Classification Report\n",
    "    Y_pred = model.predict_generator(val_generator, num_of_test_samples // BATCH_SIZE +1, verbose=1)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    target_names = [\"NV\", \"MEL\", \"BCC\", \"BKL\", \"AK\", \"SCC\", \"VASC\", \"DF\"]\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    cm = confusion_matrix(val_generator.classes, y_pred, normalize='true')\n",
    "\n",
    "    ax= plt.subplot()\n",
    "\n",
    "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted');\n",
    "    ax.set_ylabel('True'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(target_names); \n",
    "    ax.yaxis.set_ticklabels(target_names);\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig(f'/home/mrb685/Confusions/{name}.png')\n",
    "    print('Classification Report')\n",
    "    report = classification_report(val_generator.classes, y_pred, target_names=target_names, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    print(classification_report(val_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(val_generator.classes, y_pred, pos_label=2)\n",
    "    print(f\"AUC : {auc(fpr, tpr)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
